{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7RWSRJY7dnn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf, platform, os\n",
        "print(\"Python:\", platform.python_version())\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install kaggle scikit-learn opencv-python matplotlib"
      ],
      "metadata": {
        "id": "_eDLU5jA7wCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Upload kaggle.json (Account → Create New API Token on kaggle.com)\n",
        "from google.colab import files\n",
        "files.upload()  # choose kaggle.json\n",
        "\n",
        "# 2) Put it where Kaggle CLI expects\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# 3) Sanity check\n",
        "!kaggle --version"
      ],
      "metadata": {
        "id": "BvylZIxl78Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset zip to /content/data\n",
        "!mkdir -p /content/data\n",
        "!kaggle datasets download -d xhlulu/140k-real-and-fake-faces -p /content/data\n",
        "\n",
        "# Unzip quietly and overwrite if it already exists\n",
        "!rm -rf /content/data/real_vs_fake\n",
        "!unzip -qo /content/data/140k-real-and-fake-faces.zip -d /content/data\n",
        "\n",
        "# Show structure we’ll use\n",
        "!ls -la /content/data/real_vs_fake/real-vs-fake"
      ],
      "metadata": {
        "id": "5GbIWFNf7_-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32  # if you hit OOM on GPU, lower to 16 or 8\n",
        "\n",
        "TRAIN_DIR = \"/content/data/real_vs_fake/real-vs-fake/train\"\n",
        "VAL_DIR   = \"/content/data/real_vs_fake/real-vs-fake/valid\"\n",
        "\n",
        "def get_data_generators(train_dir=TRAIN_DIR, val_dir=VAL_DIR,\n",
        "                        img_size=IMG_SIZE, batch_size=BATCH_SIZE, seed=42):\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    val_datagen   = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_gen = train_datagen.flow_from_directory(\n",
        "        train_dir, target_size=img_size, batch_size=batch_size,\n",
        "        class_mode='binary', color_mode='rgb', seed=seed\n",
        "    )\n",
        "    val_gen = val_datagen.flow_from_directory(\n",
        "        val_dir, target_size=img_size, batch_size=batch_size,\n",
        "        class_mode='binary', color_mode='rgb', shuffle=False\n",
        "    )\n",
        "    return train_gen, val_gen\n",
        "\n",
        "train_gen, val_gen = get_data_generators()\n",
        "print(\"Train samples:\", train_gen.samples, \"| Val samples:\", val_gen.samples)\n",
        "print(\"Classes:\", train_gen.class_indices)"
      ],
      "metadata": {
        "id": "Z7FhvKUB8Eec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "EPOCHS = 3  # start small; raise to 10–15 once you confirm it runs\n",
        "OUT_DIR = \"/content/outputs\"\n",
        "MODELS_DIR = f\"{OUT_DIR}/models\"\n",
        "RESULTS_DIR = f\"{OUT_DIR}/results\"\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "def build_model(input_shape=(224, 224, 3)):\n",
        "    try:\n",
        "        print(\"Trying EfficientNetB0 with ImageNet weights…\")\n",
        "        base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Could not load ImageNet weights, falling back to random init.\\n\", e)\n",
        "        base = EfficientNetB0(weights=None, include_top=False, input_shape=input_shape)\n",
        "    base.trainable = False\n",
        "    x = GlobalAveragePooling2D()(base.output)\n",
        "    x = Dropout(0.4)(x)\n",
        "    out = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=base.input, outputs=out)\n",
        "    model.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = build_model((IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(f\"{MODELS_DIR}/deepfake_efficientnetb0.h5\",\n",
        "                    save_best_only=True, monitor='val_accuracy', mode='max'),\n",
        "    EarlyStopping(patience=3, restore_best_weights=True, monitor='val_accuracy', mode='max'),\n",
        "    ReduceLROnPlateau(patience=2, factor=0.5, monitor='val_loss')\n",
        "]"
      ],
      "metadata": {
        "id": "lz9Sauku8kfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = model.fit(train_gen, validation_data=val_gen,\n",
        "                    epochs=EPOCHS, callbacks=callbacks, verbose=1)\n",
        "\n",
        "# Save class indices mapping\n",
        "with open(f\"{MODELS_DIR}/class_indices.json\", \"w\") as f:\n",
        "    json.dump(train_gen.class_indices, f, indent=2)\n",
        "\n",
        "# Plot & save training curves\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'], label='train_acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
        "plt.title('Accuracy'); plt.xlabel('epoch'); plt.ylabel('acc'); plt.legend()\n",
        "plt.savefig(f\"{RESULTS_DIR}/acc_curve.png\"); plt.close()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.title('Loss'); plt.xlabel('epoch'); plt.ylabel('loss'); plt.legend()\n",
        "plt.savefig(f\"{RESULTS_DIR}/loss_curve.png\"); plt.close()\n",
        "\n",
        "print(\"Saved model to:\", f\"{MODELS_DIR}/deepfake_efficientnetb0.h5\")\n",
        "print(\"Saved curves to:\", RESULTS_DIR)"
      ],
      "metadata": {
        "id": "i8Q4Rxsw8qFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model_path = f\"{MODELS_DIR}/deepfake_efficientnetb0.h5\"\n",
        "if not os.path.exists(model_path):\n",
        "    raise FileNotFoundError(\"Model not found. Run the training cell first.\")\n",
        "\n",
        "model = load_model(model_path)\n",
        "\n",
        "# fresh val generator (no shuffle)\n",
        "_, val_gen_eval = get_data_generators()\n",
        "\n",
        "preds = model.predict(val_gen_eval, verbose=1).ravel()\n",
        "y_pred = (preds >= 0.5).astype(int)\n",
        "y_true = val_gen_eval.classes\n",
        "labels = list(val_gen_eval.class_indices.keys())\n",
        "\n",
        "# classification report\n",
        "report = classification_report(y_true, y_pred, target_names=labels, zero_division=0)\n",
        "print(report)\n",
        "with open(f\"{RESULTS_DIR}/classification_report.txt\", \"w\") as f:\n",
        "    f.write(report)\n",
        "\n",
        "# confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure()\n",
        "plt.imshow(cm, cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\"); plt.colorbar()\n",
        "plt.xticks(range(len(labels)), labels, rotation=45)\n",
        "plt.yticks(range(len(labels)), labels)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{RESULTS_DIR}/confusion_matrix.png\")\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved evaluation to:\", RESULTS_DIR)"
      ],
      "metadata": {
        "id": "YyiTrNw_8try"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip outputs and download to your machine\n",
        "!zip -rq /content/outputs.zip /content/outputs\n",
        "from google.colab import files\n",
        "files.download('/content/outputs.zip')"
      ],
      "metadata": {
        "id": "YhyqieHG9UmJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}